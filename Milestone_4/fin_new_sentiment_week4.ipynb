{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fin_new_sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48fc10235c0147ee85d620e7bfd5037b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad178e10496846ad89ae8a1aa66565db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_57a465362da942a9946e6ecd43775b6b",
              "IPY_MODEL_93a2007fb3654f4a8aa510452ff2de07"
            ]
          }
        },
        "ad178e10496846ad89ae8a1aa66565db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57a465362da942a9946e6ecd43775b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_639b5c67f4d545128fdbbfedbec0bd9d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1e6cd583bbd4a7fbdeec7c53e46b18d"
          }
        },
        "93a2007fb3654f4a8aa510452ff2de07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_973c9d1e628c44e7adc7372c2599af34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 307kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a653429f985477eb529c5511dfced16"
          }
        },
        "639b5c67f4d545128fdbbfedbec0bd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1e6cd583bbd4a7fbdeec7c53e46b18d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "973c9d1e628c44e7adc7372c2599af34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a653429f985477eb529c5511dfced16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "238bc059211241be820b052592c264f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a1cba62cd7574bb0a06775e50b3a4c7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_71147ab055f5490687591e6aafb68ec4",
              "IPY_MODEL_a983776b5a32499292e2e2e54765b96b"
            ]
          }
        },
        "a1cba62cd7574bb0a06775e50b3a4c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71147ab055f5490687591e6aafb68ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a27c2b84862f443cac2e0630feab3c53",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_66e072a8037c4a518873d8ebf8b45c88"
          }
        },
        "a983776b5a32499292e2e2e54765b96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1761c0ed432644eea0a07b2505958d3d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 281B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e900f65abc9f4e819c1a78777ba41ed9"
          }
        },
        "a27c2b84862f443cac2e0630feab3c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "66e072a8037c4a518873d8ebf8b45c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1761c0ed432644eea0a07b2505958d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e900f65abc9f4e819c1a78777ba41ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1652022ef25b4d0996c4f8063b982e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2350d96541254883841dbda6e6905952",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fae928b914e434b9472777f4c649215",
              "IPY_MODEL_fdc7debb75f04541a95aaae5730c10b1"
            ]
          }
        },
        "2350d96541254883841dbda6e6905952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fae928b914e434b9472777f4c649215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1e9f44658d04afd9770d53cfc496a5d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eedd6fb5f0d74304b2c1280a91cf8447"
          }
        },
        "fdc7debb75f04541a95aaae5730c10b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f73abf4faddf4d14a2d7d8ee39397254",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [01:12&lt;00:00, 6.07MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c9381b1871b4002a46e1db8fa35f143"
          }
        },
        "d1e9f44658d04afd9770d53cfc496a5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eedd6fb5f0d74304b2c1280a91cf8447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f73abf4faddf4d14a2d7d8ee39397254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c9381b1871b4002a46e1db8fa35f143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDNfQJJmTb4P",
        "colab_type": "code",
        "outputId": "2108e880-8f8e-419e-fd1f-b1a7e9d8096e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36wNAPJzTsWe",
        "colab_type": "code",
        "outputId": "2c9712b3-6ab7-4826-ba2a-d91481a8199c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXYH0CJzT5XI",
        "colab_type": "code",
        "outputId": "0022e98c-ca48-4602-ebbb-256ad450968e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "## Set seed of randomization and working device\n",
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)\n",
        "\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJJVSeeQUAe3",
        "colab_type": "code",
        "outputId": "1a717000-9c1b-4578-88f8-f4f05da85961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 573kB 2.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 59.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7MB 48.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.0MB 46.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.43 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.43)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.43->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=cd0087e4b9e4578c25a5e289d53de13d70755ac8944f6e46581c7b87300f2371\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmeFyW5QVOKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smEk7mRnVRsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformers has a unified API\n",
        "# here we list models for 10 transformer architectures\n",
        "# for the full list of available pretrained-models: go to https://huggingface.co/transformers/pretrained_models.html\n",
        "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
        "MODELS = [(BertModel,       BertTokenizer,       'bert-base-uncased'),\n",
        "          (OpenAIGPTModel,  OpenAIGPTTokenizer,  'openai-gpt'),\n",
        "          (GPT2Model,       GPT2Tokenizer,       'gpt2'),\n",
        "          (CTRLModel,       CTRLTokenizer,       'ctrl'),\n",
        "          (TransfoXLModel,  TransfoXLTokenizer,  'transfo-xl-wt103'),\n",
        "          (XLNetModel,      XLNetTokenizer,      'xlnet-base-cased'),\n",
        "          (XLMModel,        XLMTokenizer,        'xlm-mlm-enfr-1024'),\n",
        "          (DistilBertModel, DistilBertTokenizer, 'distilbert-base-cased'),\n",
        "          (RobertaModel,    RobertaTokenizer,    'roberta-base'),\n",
        "          (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
        "         ]\n",
        "         \n",
        "# Each architecture is provided with several class for fine-tuning on down-stream tasks, e.g.\n",
        "BERT_MODEL_CLASSES = [BertModel, BertForPreTraining, BertForMaskedLM, BertForNextSentencePrediction,\n",
        "                      BertForSequenceClassification, BertForTokenClassification, BertForQuestionAnswering]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAU9FyKPWzLM",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVk4bhE_V1SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define a function for data preparation\n",
        "def data_prepare(file_path, tokenizer, lab2ind, max_len = 32, mode = 'train'):\n",
        "    '''\n",
        "    file_path: the path to input file. \n",
        "                In train mode, the input must be a csv file that includes two columns where the first is text, and second column is label.\n",
        "                The first row must be header of columns.\n",
        "\n",
        "                In predict mode, the input must be a tsv file that includes only one column where the first is text.\n",
        "                The first row must be header of column.\n",
        "\n",
        "    lab2ind: dictionary of label classes\n",
        "    tokenizer: BERT tokenizer\n",
        "    max_len: maximal length of input sequence\n",
        "    mode: train or predict\n",
        "    '''\n",
        "    # if we are in train mode, we will load two columns (i.e., text and label).\n",
        "    if mode == 'train':\n",
        "        # Use pandas to load dataset\n",
        "        df = pd.read_csv(file_path, header=0, names=['content','label'])\n",
        "        print(\"Data size \", df.shape)\n",
        "        labels = df.label.values\n",
        "        \n",
        "        # Create sentence and label lists\n",
        "        labels = [lab2ind[label] for label in labels] \n",
        "        print(\"Label is \", labels[0])\n",
        "        \n",
        "        # Convert data into torch tensors\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "    # if we are in predict mode, we will load one column (i.e., text).\n",
        "    elif mode == 'predict':\n",
        "        df = pd.read_csv(file_path, header=0, names=['content'])\n",
        "        print(\"Data size \", df.shape)\n",
        "        # create placeholder\n",
        "        labels = []\n",
        "    else:\n",
        "        print(\"the type of mode should be either 'train' or 'predict'. \")\n",
        "        return\n",
        "        \n",
        "    # Create sentence and label lists\n",
        "    content = df.content.values\n",
        "\n",
        "    # We need to add a special token at the beginning for BERT to work properly.\n",
        "    content = [\"[CLS] \" + text for text in content]\n",
        "\n",
        "    # Import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary.\n",
        "    tokenized_texts = [tokenizer.tokenize(text) for text in content]\n",
        "\n",
        "    \n",
        "    # if the sequence is longer the maximal length, we truncate it to the pre-defined maximal length\n",
        "    tokenized_texts = [ text[:max_len+1] for text in tokenized_texts]\n",
        "\n",
        "    # We also need to add a special token at the end.\n",
        "    tokenized_texts = [ text+['[SEP]'] for text in tokenized_texts]\n",
        "    print (\"Tokenize the first sentence:\\n\",tokenized_texts[0])\n",
        "    \n",
        "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    print (\"Index numbers of the first sentence:\\n\",input_ids[0])\n",
        "\n",
        "    # Pad our input seqeunce to the fixed length (i.e., max_len) with index of [PAD] token\n",
        "    pad_ind = tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n",
        "    input_ids = pad_sequences(input_ids, maxlen=max_len+2, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_ind)\n",
        "    # input_ids = pad_sequences(input_ids, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_ind)\n",
        "    print (\"Index numbers of the first sentence after padding:\\n\",input_ids[0])\n",
        "\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for pad tokens\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # Convert all of our data into torch tensors, the required datatype for our model\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, labels, masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-InRperTPr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# eco_news_pd = pd.read_json('./drive/My Drive/datasetEconomyNews_PN.json')\n",
        "# train, valid = train_test_split(eco_news_pd, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mckPoL67N3ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Don't run this block! This code is used to run the models on either headlineText or headlineTitle\n",
        "\n",
        "#def json_data_prepare(dataset, tokenizer, lab2ind, mode = 'train'):\n",
        "#    '''\n",
        "#    file_path: the path to input file. \n",
        "#            In train mode, the input must be a csv file that includes two columns where the first is text, and second column is label.\n",
        "#            The first row must be header of columns.\n",
        "#\n",
        "#            In predict mode, the input must be a tsv file that includes only one column where the first is text.\n",
        "#            The first row must be header of column.\n",
        "#\n",
        "#    lab2ind: dictionary of label classes\n",
        "#    tokenizer: BERT tokenizer\n",
        "#    max_len: maximal length of input sequence\n",
        "#    mode: train or predict\n",
        "#    '''\n",
        "#\n",
        "#    if mode == 'train':\n",
        "#        #print(\"Data size \", dataset.shape)\n",
        "#        labels = dataset.classification.values\n",
        "#        \n",
        "#\n",
        "#        # Create sentence and label lists\n",
        "#        labels = [lab2ind[label] for label in labels] \n",
        "#         \n",
        "#\n",
        "#        print(\"Label is \", labels[0])\n",
        "#        # Convert data into torch tensors\n",
        "#\n",
        "#        labels = torch.tensor(labels)\n",
        "#    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Create sentence and label lists\n",
        "#     content = dataset.headlineText.values\n",
        "  \n",
        "\n",
        "    # We need to add a special token at the beginning for BERT to work properly.\n",
        " #    content = [\"[CLS] \" + text for text in content]\n",
        "  \n",
        "\n",
        "    # Import the BERT tokenizer, used to convert our text into tokens that correspond to BERT's vocabulary.\n",
        "#   tokenized_texts = [tokenizer.tokenize(text) for text in content]\n",
        "\n",
        "    \n",
        "    # if the sequence is longer the maximal length, we truncate it to the pre-defined maximal length\n",
        "    #tokenized_texts = [ text[:max_len+1] for text in tokenized_texts]\n",
        "\n",
        "    # We also need to add a special token at the end.\n",
        "#    tokenized_texts = [ text+['[SEP]'] for text in tokenized_texts]\n",
        "#    print (\"Tokenize the first sentence:\\n\",tokenized_texts[0])\n",
        "    \n",
        "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "#     input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "#     print (\"Index numbers of the first sentence:\\n\",input_ids[0])\n",
        "\n",
        "    # Pad our input seqeunce to the fixed length (i.e., max_len) with index of [PAD] token\n",
        "#     pad_ind = tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n",
        "#     input_ids = pad_sequences(input_ids, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_ind)\n",
        "    # input_ids = pad_sequences(input_ids, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_ind)\n",
        "#     print (\"Index numbers of the first sentence after padding:\\n\",input_ids[0])\n",
        "\n",
        "    # Create attention masks\n",
        "#     attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for pad tokens\n",
        "#     for seq in input_ids:\n",
        "#         seq_mask = [float(i>0) for i in seq]\n",
        "#         attention_masks.append(seq_mask)\n",
        "\n",
        "    # Convert all of our data into torch tensors, the required datatype for our model\n",
        "#     inputs = torch.tensor(input_ids)\n",
        "#     masks = torch.tensor(attention_masks)\n",
        "\n",
        "#     return inputs, labels, masks\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHr4GUN-t1rS",
        "colab_type": "code",
        "outputId": "664a5508-7e5e-4c7f-9e9e-e9fe422d19e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "48fc10235c0147ee85d620e7bfd5037b",
            "ad178e10496846ad89ae8a1aa66565db",
            "57a465362da942a9946e6ecd43775b6b",
            "93a2007fb3654f4a8aa510452ff2de07",
            "639b5c67f4d545128fdbbfedbec0bd9d",
            "a1e6cd583bbd4a7fbdeec7c53e46b18d",
            "973c9d1e628c44e7adc7372c2599af34",
            "0a653429f985477eb529c5511dfced16"
          ]
        }
      },
      "source": [
        "model_path = \"bert-base-uncased\"\n",
        "# define label to number dictionary\n",
        "lab2ind = {-1: 0, 1: 1}\n",
        "\n",
        "# tokenizer from pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48fc10235c0147ee85d620e7bfd5037b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tCo57WJU5Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_inputs, train_labels, train_masks = json_data_prepare(train, tokenizer, lab2ind)\n",
        "#validation_inputs, validation_labels, validation_masks = json_data_prepare(valid, tokenizer, lab2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HuLIT7rtX5U",
        "colab_type": "code",
        "outputId": "c16d6d91-faf2-4454-ae00-c7af1ae4233c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "# Use defined funtion to extract data\n",
        "train_inputs, train_labels, train_masks = data_prepare('./drive/My Drive/finance_news_data/finan_news_train.csv', tokenizer, lab2ind)\n",
        "validation_inputs, validation_labels, validation_masks = data_prepare('./drive/My Drive/finance_news_data/finan_news_dev.csv', tokenizer, lab2ind)\n",
        "#test_inputs, test_labels, test_masks = data_prepare('./drive/My Drive/finance_news_data/finan_news_test.csv', tokenizer, lab2ind, mode = 'predict')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size  (786, 2)\n",
            "Label is  0\n",
            "Tokenize the first sentence:\n",
            " ['[CLS]', '\"', 'u', '.', 's', '.', 'economic', 'growth', 'has', 'sharply', 'dec', '##ele', '##rated', 'since', 'early', 'december', '.', 'in', 'the', 'current', 'macro', 'environment', ',', 'we', 'recommend', 'investors', 'own', 'stocks', '.', '[SEP]']\n",
            "Index numbers of the first sentence:\n",
            " [101, 1000, 1057, 1012, 1055, 1012, 3171, 3930, 2038, 9249, 11703, 12260, 9250, 2144, 2220, 2285, 1012, 1999, 1996, 2783, 26632, 4044, 1010, 2057, 16755, 9387, 2219, 15768, 1012, 102]\n",
            "Index numbers of the first sentence after padding:\n",
            " [  101  1000  1057  1012  1055  1012  3171  3930  2038  9249 11703 12260\n",
            "  9250  2144  2220  2285  1012  1999  1996  2783 26632  4044  1010  2057\n",
            " 16755  9387  2219 15768  1012   102     0     0     0     0]\n",
            "Data size  (169, 2)\n",
            "Label is  1\n",
            "Tokenize the first sentence:\n",
            " ['[CLS]', 'or', '2', ')', 'it', \"'\", 's', 'a', 'sign', 'of', 'a', 'strengthening', 'economy', ',', 'which', 'means', 'inflation', 'will', 'pick', 'up', 'and', '.', 'latter', 'view', ',', 'and', 'they', 'believe', 'rising', 'rates', 'are', 'probably', 'good', '[SEP]']\n",
            "Index numbers of the first sentence:\n",
            " [101, 2030, 1016, 1007, 2009, 1005, 1055, 1037, 3696, 1997, 1037, 16003, 4610, 1010, 2029, 2965, 14200, 2097, 4060, 2039, 1998, 1012, 3732, 3193, 1010, 1998, 2027, 2903, 4803, 6165, 2024, 2763, 2204, 102]\n",
            "Index numbers of the first sentence after padding:\n",
            " [  101  2030  1016  1007  2009  1005  1055  1037  3696  1997  1037 16003\n",
            "  4610  1010  2029  2965 14200  2097  4060  2039  1998  1012  3732  3193\n",
            "  1010  1998  2027  2903  4803  6165  2024  2763  2204   102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4Iy6gVGuEeh",
        "colab_type": "code",
        "outputId": "049a43cc-5b64-4b38-b1ff-1cab4fcca851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_inputs.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([786, 34])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mTuGcso5Vow",
        "colab_type": "code",
        "outputId": "52cf0bc7-54c5-4ff7-f886-14ebab0cd033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "test_inputs, test_labels, test_masks = data_prepare('./drive/My Drive/finance_news_data/finan_news_test.csv', tokenizer, lab2ind)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data size  (169, 2)\n",
            "Label is  0\n",
            "Tokenize the first sentence:\n",
            " ['[CLS]', 'sound', '##cl', '##oud', ',', 'the', 'world', \"'\", 's', 'biggest', 'music', '-', 'streaming', 'service', ',', 'is', 'still', 'struggling', 'to', 'find', 'a', 'business', 'model', '-', 'it', 'now', 'has', 'enough', 'cash', 'to', 'last', 'until', 'fourth', '[SEP]']\n",
            "Index numbers of the first sentence:\n",
            " [101, 2614, 20464, 19224, 1010, 1996, 2088, 1005, 1055, 5221, 2189, 1011, 11058, 2326, 1010, 2003, 2145, 8084, 2000, 2424, 1037, 2449, 2944, 1011, 2009, 2085, 2038, 2438, 5356, 2000, 2197, 2127, 2959, 102]\n",
            "Index numbers of the first sentence after padding:\n",
            " [  101  2614 20464 19224  1010  1996  2088  1005  1055  5221  2189  1011\n",
            " 11058  2326  1010  2003  2145  8084  2000  2424  1037  2449  2944  1011\n",
            "  2009  2085  2038  2438  5356  2000  2197  2127  2959   102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN3z58yu5WY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z0QWbPx9Iw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "# We'll take training samples in random order in each epoch. \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, \n",
        "                              sampler = RandomSampler(train_data), # Select batches randomly\n",
        "                              batch_size=batch_size)\n",
        "\n",
        "# We'll just read validation set sequentially.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_dataloader = DataLoader(validation_data, \n",
        "                                   sampler = SequentialSampler(validation_data), # Pull out batches sequentially.\n",
        "                                   batch_size=batch_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4X8iTeU6HXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                             sampler = SequentialSampler(test_data),\n",
        "                             batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlqDi01K_pgn",
        "colab_type": "text"
      },
      "source": [
        "## Loading pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwAydNeU9sg1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "238bc059211241be820b052592c264f7",
            "a1cba62cd7574bb0a06775e50b3a4c7a",
            "71147ab055f5490687591e6aafb68ec4",
            "a983776b5a32499292e2e2e54765b96b",
            "a27c2b84862f443cac2e0630feab3c53",
            "66e072a8037c4a518873d8ebf8b45c88",
            "1761c0ed432644eea0a07b2505958d3d",
            "e900f65abc9f4e819c1a78777ba41ed9",
            "1652022ef25b4d0996c4f8063b982e26",
            "2350d96541254883841dbda6e6905952",
            "3fae928b914e434b9472777f4c649215",
            "fdc7debb75f04541a95aaae5730c10b1",
            "d1e9f44658d04afd9770d53cfc496a5d",
            "eedd6fb5f0d74304b2c1280a91cf8447",
            "f73abf4faddf4d14a2d7d8ee39397254",
            "3c9381b1871b4002a46e1db8fa35f143"
          ]
        },
        "outputId": "baed3e72-44ef-4ef1-b770-17af7bfe32af"
      },
      "source": [
        "model_path = \"bert-base-uncased\"\n",
        "\n",
        "bert_model = BertModel.from_pretrained(model_path, output_hidden_states=True, output_attentions=True).to(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "238bc059211241be820b052592c264f7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1652022ef25b4d0996c4f8063b982e26",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzSJq_WfOtBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(train_dataloader)\n",
        "batch = dataiter.next()\n",
        "# Add batch to GPU\n",
        "batch = tuple(t.to(device) for t in batch)\n",
        "# Unpack the inputs from our dataloader\n",
        "input_ids, input_mask, labels = batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy-lujHQWFL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last_hidden_state, pooler_output, hidden_states, attentions = bert_model(input_ids, attention_mask = input_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI00JbGAWKcv",
        "colab_type": "code",
        "outputId": "98f608eb-0df0-4e47-9332-b389a6c07b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 34, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7-3UlfXWOUN",
        "colab_type": "code",
        "outputId": "bb1bce9d-149a-4c37-eb79-4a8e2cc06ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pooler_output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LujDMus_Wl3z",
        "colab_type": "text"
      },
      "source": [
        "## Creating `Bert_cls` class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4oAoAaXWStt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bert_cls(nn.Module):\n",
        "    def __init__(self, model_path, hidden_size):\n",
        "        super(Bert_cls, self).__init__()\n",
        "        self.model_path = model_path\n",
        "        self.hidden_size = hidden_size\n",
        "        self.bert_model = BertModel.from_pretrained(model_path, output_hidden_states=True, output_attentions=True)\n",
        "        self.label_num = 2\n",
        "        self.fc = nn.Linear(self.hidden_size, self.label_num)\n",
        "    def forward(self, bert_ids, bert_mask):\n",
        "        last_hidden_state, pooler_output, hidden_states, attentions = self.bert_model(input_ids=bert_ids)\n",
        "        fc_output = self.fc(pooler_output)\n",
        "        return fc_output, attentions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyGsCz1sYmoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = Bert_cls('bert-base-uncased', 768).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSk5ETlSY4SE",
        "colab_type": "text"
      },
      "source": [
        "## Optimizer and Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n7fDxlxYt1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters:\n",
        "lr = 2e-5\n",
        "max_grad_norm = 1.0\n",
        "epochs = 10\n",
        "warmup_proportion = 0.1\n",
        "num_training_steps  = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * warmup_proportion\n",
        "\n",
        "### In Transformers, optimizer and schedules are instantiated like this:\n",
        "# Note: AdamW is a class from the huggingface library\n",
        "# the 'W' stands for 'Weight Decay\"\n",
        "optimizer = AdamW(bert_model.parameters(), lr=lr, correct_bias=False)\n",
        "# schedules\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n",
        "\n",
        "# We use nn.CrossEntropyLoss() as our loss function. \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92x8syWBZ7BJ",
        "colab_type": "text"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnF4yxscZy1L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, scheduler, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        input_ids, input_mask, labels = batch\n",
        "\n",
        "        outputs,_ = model(input_ids, input_mask)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        # delete used variables to free GPU memory\n",
        "        del batch, input_ids, input_mask, labels\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping is not in AdamW anymore\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss += loss.cpu().item()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    # free GPU memory\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKm4VmOdaBFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            input_ids, input_mask, labels = batch\n",
        "\n",
        "            outputs,_ = model(input_ids, input_mask)\n",
        "            \n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # delete used variables to free GPU memory\n",
        "            del batch, input_ids, input_mask\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return epoch_loss / len(iterator), accuracy, f1score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VrfrjUkaHX9",
        "colab_type": "code",
        "outputId": "97bf7999-020d-4d39-f06d-623338ac1c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "# Train the model\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(epochs, desc=\"Epoch\"):\n",
        "    train_loss = train(bert_model, train_dataloader, optimizer, scheduler, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(bert_model, validation_dataloader, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': bert_model.state_dict(),\n",
        "        'optimizer': optimizer.state_dict(),\n",
        "        'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/My Drive/finance_news_data/ckpt_BERT/BERT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, epochs, train_loss, val_loss, val_acc, val_f1))\n",
        "    "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  10%|â–ˆ         | 1/10 [00:08<01:19,  8.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [1/10], Train Loss: 0.6514, Validation Loss: 0.7536, Validation Accuracy: 0.4438, Validation F1: 0.4438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|â–ˆâ–ˆ        | 2/10 [00:33<01:48, 13.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [2/10], Train Loss: 0.6343, Validation Loss: 0.4687, Validation Accuracy: 0.8047, Validation F1: 0.7984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [01:07<02:17, 19.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [3/10], Train Loss: 0.3857, Validation Loss: 0.5179, Validation Accuracy: 0.7929, Validation F1: 0.7694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:43<02:27, 24.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [4/10], Train Loss: 0.1683, Validation Loss: 0.8709, Validation Accuracy: 0.7929, Validation F1: 0.7793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [02:15<02:14, 26.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [5/10], Train Loss: 0.0861, Validation Loss: 0.8240, Validation Accuracy: 0.8225, Validation F1: 0.8154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [02:44<01:49, 27.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [6/10], Train Loss: 0.0311, Validation Loss: 0.8112, Validation Accuracy: 0.8166, Validation F1: 0.8097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [03:19<01:29, 29.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [7/10], Train Loss: 0.0088, Validation Loss: 1.0011, Validation Accuracy: 0.8225, Validation F1: 0.8171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [03:47<00:58, 29.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [8/10], Train Loss: 0.0110, Validation Loss: 1.1067, Validation Accuracy: 0.8284, Validation F1: 0.8228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [04:25<00:31, 31.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [9/10], Train Loss: 0.0014, Validation Loss: 1.1376, Validation Accuracy: 0.8225, Validation F1: 0.8171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [04:58<00:00, 29.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [10/10], Train Loss: 0.0040, Validation Loss: 1.1333, Validation Accuracy: 0.8284, Validation F1: 0.8228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwp1MYto9pAL",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQjjLzNhbgZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters:\n",
        "lr = 2e-5\n",
        "max_grad_norm = 1.0\n",
        "# epochs = 3\n",
        "warmup_proportion = 0.1\n",
        "num_training_steps  = len(train_dataloader) * epochs\n",
        "num_warmup_steps = num_training_steps * warmup_proportion\n",
        "\n",
        "### In Transformers, optimizer and schedules are instantiated like this:\n",
        "# Note: AdamW is a class from the huggingface library\n",
        "# the 'W' stands for 'Weight Decay\"\n",
        "optimizer = AdamW(bert_model.parameters(), lr=lr, correct_bias=False)\n",
        "# schedules\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler\n",
        "\n",
        "# We use nn.CrossEntropyLoss() as our loss function. \n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otJTTrXvkh68",
        "colab_type": "text"
      },
      "source": [
        "# Bert-Large\n",
        "Don't run this cell if testing Bert-Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIiRO-BG3_k8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e418d53-9908-4151-dac6-eb4c5d2432b7"
      },
      "source": [
        "bert_model_best = Bert_cls('bert-large-uncased', 1024).to(device)\n",
        "bert_model_best.load_state_dict(torch.load('./drive/My Drive/finance_news_data/ckpt_BERT/BERT_2.pt')['state_dict'])\n",
        "test_loss, test_acc, test_f1 = evaluate(bert_model_best, test_dataloader, criterion)\n",
        "print('f1 score on test set for Bert large is',test_f1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score on test set for Bert large is 0.7763282283985631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-05ZIDQlDtj",
        "colab_type": "text"
      },
      "source": [
        "# Bert-Base\n",
        "Don't run this block if testing Bert-Base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7zmdUWelK4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1388edc7-4542-4d66-9077-a702c4c92004"
      },
      "source": [
        "bert_model_best = Bert_cls('bert-base-uncased', 768).to(device)\n",
        "bert_model_best.load_state_dict(torch.load('./drive/My Drive/finance_news_data/ckpt_BERT/BERT_8.pt')['state_dict'])\n",
        "test_loss, test_acc, test_f1 = evaluate(bert_model_best, test_dataloader, criterion)\n",
        "print('f1 score on test set for Bert base is',test_f1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 score on test set for Bert base is 0.8297197447475463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqyvZb52oc5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}