{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finan_news_CNN_text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0WiI4eL_dbL",
        "colab_type": "code",
        "outputId": "9f90cf02-0290-49e0-a145-a56c6f757b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCUGWXk7_jI_",
        "colab_type": "code",
        "outputId": "3e7180fd-cdaf-4fee-d31b-f3cae83172a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "!pip install -U torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/70/54e9fb010fe1547bc4774716f11ececb81ae5b306c05f090f4461ee13205/torch-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (752.0MB)\n",
            "\u001b[K     |████████████████████████████████| 752.0MB 22kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "\u001b[31mERROR: torchvision 0.5.0 has requirement torch==1.4.0, but you'll have torch 1.5.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.4.0\n",
            "    Uninstalling torch-1.4.0:\n",
            "      Successfully uninstalled torch-1.4.0\n",
            "Successfully installed torch-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LjV0fhaAM0v",
        "colab_type": "code",
        "outputId": "1629cb84-3142-4500-aec0-a431a9961e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHCvUt9J_uOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data import Field, LabelField\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import Iterator, BucketIterator\n",
        "import spacy\n",
        "import en_core_web_sm\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "from tqdm import tqdm, trange\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoOvBVX0__q8",
        "colab_type": "code",
        "outputId": "879f50fa-ec42-4700-b060-8b7ba15da22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "## Set seed of randomization and working device\n",
        "manual_seed = 77\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_gpu = torch.cuda.device_count()\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed(manual_seed)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REdt_Pk5AClX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spacy_en = en_core_web_sm.load()\n",
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U612YV5eAY4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "TEXT = Field(sequential=True, tokenize=tokenize_en, lower=True)\n",
        "LABEL = Field(sequential=False, unk_token = None)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0W4E4EXAZY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val, test = TabularDataset.splits(\n",
        "               path=\"/content/drive/My Drive/Colab Notebooks/Block-6_NJS/financial_analysis/Milestone_3/finance_news_data/\", # the root directory where the data lies\n",
        "               train='finan_news_train-text.csv', validation=\"finan_news_dev-text.csv\", test=\"finan_news_test-text.csv\", # file names\n",
        "               format='csv',\n",
        "               skip_header=True, # if your tsv file has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
        "               fields=[('X', TEXT), ('y', LABEL)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XE5BIQDA1db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(train, min_freq=2)\n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waKe_2ItA4BK",
        "colab_type": "code",
        "outputId": "1fe0980b-2805-48eb-9c95-0f98bea75b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Vocabulary size of TEXT:\",len(TEXT.vocab.stoi))\n",
        "print(\"Vocabulary size of LABEL:\",len(LABEL.vocab.stoi))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size of TEXT: 1159\n",
            "Vocabulary size of LABEL: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPYwySSEBMFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        " (train, val, test), # we pass in the datasets we want the iterator to draw data from\n",
        " batch_sizes=(64,256,256),\n",
        " sort_key=lambda x: len(x.X), \n",
        " sort=True,\n",
        "# A key to use for sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
        " sort_within_batch=True\n",
        ")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Pve46UBQED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# To define a CNN class\n",
        "class CNN_Text(nn.Module):\n",
        "    def __init__(self, vocabulary_size, embedding_dim, output_size, kernel_num, region_sizes, dropout):\n",
        "        '''\n",
        "        vocabulary_size: vocabulary size\n",
        "        embedding_dim: word embedding size\n",
        "        output_size: number of classes in prediction\n",
        "        kernel_num: number of kernels (number of output channels of convolutional layers)\n",
        "        region_sizes: height of kernels of convolutional layers\n",
        "        dropout: dropout rate\n",
        "        '''\n",
        "        super(CNN_Text, self).__init__()\n",
        "        # the size of input channel is 1.\n",
        "        Ci = 1\n",
        "        \n",
        "        # word embedding layer\n",
        "        self.embeddings = nn.Embedding(num_embeddings = vocabulary_size, embedding_dim = embedding_dim )\n",
        "        \n",
        "        # convolution with kernels\n",
        "        self.convolution_layers = nn.ModuleList([nn.Conv2d(in_channels = Ci, out_channels = kernel_num, kernel_size = (K, embedding_dim)) for K in region_sizes])\n",
        "        \n",
        "        # a dropout layer\n",
        "        self.dropout = nn.Dropout(dropout) \n",
        "        \n",
        "        # fully connected layer\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * kernel_num, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input x  [sequence length, batch size]\n",
        "        \n",
        "        input_embeddings = self.embeddings(x)  \n",
        "        # (batch size, word_sequence, embedding_dim) word embedding\n",
        "\n",
        "        input_embeddings = input_embeddings.permute(1,0,2)\n",
        "        input_embeddings = input_embeddings.unsqueeze(1)\n",
        "        #  [batch size, number of channel is one, sequence length, embeeding size]\n",
        "\n",
        "        # convolutional layers\n",
        "        convolute_outputs = [F.relu(conv(input_embeddings)).squeeze(3) for conv in self.convolution_layers]  \n",
        "        \n",
        "        # to get the maximum value of filtered tensor\n",
        "        max_pooling_outputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convolute_outputs] \n",
        "        \n",
        "        concat_list = torch.cat(max_pooling_outputs, 1) # concatenate representations\n",
        "        \n",
        "        drop_output = self.dropout(concat_list)  # add drop layer\n",
        "        \n",
        "        fc1_output = self.fc(drop_output)  # get the fc1 using a fully connected layer\n",
        "        \n",
        "        final_output = F.softmax(fc1_output,dim=1)\n",
        "        \n",
        "        return final_output\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mna1HD-EBR_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Hyper Parameters\n",
        "\n",
        "# the vocabulary size\n",
        "vocabulary_size = len(TEXT.vocab.stoi) \n",
        "\n",
        "# Dimension of word embedding is 300. Namely, each word is expressed by a vector that has 300 dimensions.\n",
        "embedding_dim = 300 \n",
        "\n",
        "# region size as 2, 3, and 4\n",
        "kernel_sizes = [2,3,4] \n",
        "\n",
        "# the number of kernel in each region size\n",
        "kernels_num = 32  \n",
        "\n",
        "# The dropout rate is set to be 0.5.\n",
        "dropout = 0.5\n",
        "\n",
        "# The output size of labels.\n",
        "output_size = 2\n",
        "\n",
        "# learning rate is set to be 0.01.\n",
        "lr = 0.01        \n",
        "\n",
        "# The number of iteration is set to be 5.\n",
        "num_epoch = 5  \n",
        "\n",
        "# employ class CNN_Text and assign to cnn\n",
        "model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout).to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxzmLHrhBmss",
        "colab_type": "code",
        "outputId": "62fefe7b-e182-4a34-c91e-2017aa9126ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.1)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN_Text(\n",
              "  (embeddings): Embedding(1159, 300)\n",
              "  (convolution_layers): ModuleList(\n",
              "    (0): Conv2d(1, 32, kernel_size=(2, 300), stride=(1, 1))\n",
              "    (1): Conv2d(1, 32, kernel_size=(3, 300), stride=(1, 1))\n",
              "    (2): Conv2d(1, 32, kernel_size=(4, 300), stride=(1, 1))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=96, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqyySIdjBpdb",
        "colab_type": "code",
        "outputId": "4dcae6f2-c5e1-41dc-af60-0d9280d89a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 434,390 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IolHvSD1CLh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss and optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # define a optimizer for backpropagation\n",
        "criterion = nn.CrossEntropyLoss()   # define loss funtion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EBO6rBxCOJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        batch_input, labels = batch.X, batch.y\n",
        "        batch_input = batch_input.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = model(batch_input)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.cpu().item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlRF_R4RCQv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            batch_input, labels = batch.X, batch.y\n",
        "            batch_input = batch_input.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(batch_input)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            epoch_loss += loss.cpu().item()\n",
        "\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(labels.cpu())\n",
        "    \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='macro') \n",
        "    return epoch_loss / len(iterator), accuracy, f1score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVTmrTmZCTlb",
        "colab_type": "code",
        "outputId": "74e46e48-eb6b-4310-e5a7-a8b2baa920b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        }
      },
      "source": [
        "\n",
        "\n",
        "# Train the model\n",
        "MAX_EPOCH = 15\n",
        "total_step = len(train_iter)\n",
        "loss_list = []\n",
        "acc_list = []\n",
        "\n",
        "for epoch in trange(MAX_EPOCH, desc=\"Epoch\"):\n",
        "    train_loss = train(model, train_iter, optimizer, criterion)  \n",
        "    val_loss, val_acc, val_f1 = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    # Create checkpoint at end of each epoch\n",
        "    state_dict_model = model.state_dict() \n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'state_dict': state_dict_model,\n",
        "        'optimizer': optimizer.state_dict()\n",
        "        }\n",
        "\n",
        "    torch.save(state, \"./drive/My Drive/Colab Notebooks/CNN_TEXT_\"+str(epoch+1)+\".pt\")\n",
        "\n",
        "    print('\\n Epoch [{}/{}], Train Loss: {:.4f}, Validation Loss: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCH, train_loss, val_loss, val_acc, val_f1))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:   7%|▋         | 1/15 [00:01<00:25,  1.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [1/15], Train Loss: 0.7117, Validation Loss: 0.6466, Validation Accuracy: 0.6667, Validation F1: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  13%|█▎        | 2/15 [00:03<00:23,  1.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [2/15], Train Loss: 0.7001, Validation Loss: 0.6466, Validation Accuracy: 0.6667, Validation F1: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 3/15 [00:05<00:21,  1.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [3/15], Train Loss: 0.6623, Validation Loss: 0.6465, Validation Accuracy: 0.6310, Validation F1: 0.5295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  27%|██▋       | 4/15 [00:07<00:19,  1.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [4/15], Train Loss: 0.6266, Validation Loss: 0.6463, Validation Accuracy: 0.6667, Validation F1: 0.4000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 5/15 [00:08<00:17,  1.79s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [5/15], Train Loss: 0.5718, Validation Loss: 0.7049, Validation Accuracy: 0.5119, Validation F1: 0.5085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 6/15 [00:10<00:16,  1.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [6/15], Train Loss: 0.5882, Validation Loss: 0.6064, Validation Accuracy: 0.7143, Validation F1: 0.6583\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  47%|████▋     | 7/15 [00:12<00:14,  1.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [7/15], Train Loss: 0.4467, Validation Loss: 0.6230, Validation Accuracy: 0.6786, Validation F1: 0.6415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  53%|█████▎    | 8/15 [00:14<00:12,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [8/15], Train Loss: 0.3960, Validation Loss: 0.6278, Validation Accuracy: 0.6548, Validation F1: 0.5599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 9/15 [00:15<00:10,  1.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [9/15], Train Loss: 0.3693, Validation Loss: 0.6343, Validation Accuracy: 0.6548, Validation F1: 0.5822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 10/15 [00:17<00:08,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [10/15], Train Loss: 0.3759, Validation Loss: 0.6677, Validation Accuracy: 0.6071, Validation F1: 0.5753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  73%|███████▎  | 11/15 [00:19<00:07,  1.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [11/15], Train Loss: 0.3583, Validation Loss: 0.5939, Validation Accuracy: 0.7262, Validation F1: 0.6406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 12/15 [00:21<00:05,  1.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [12/15], Train Loss: 0.3360, Validation Loss: 0.6052, Validation Accuracy: 0.6786, Validation F1: 0.6351\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  87%|████████▋ | 13/15 [00:22<00:03,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [13/15], Train Loss: 0.3446, Validation Loss: 0.5913, Validation Accuracy: 0.7143, Validation F1: 0.6500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  93%|█████████▎| 14/15 [00:24<00:01,  1.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [14/15], Train Loss: 0.3315, Validation Loss: 0.5870, Validation Accuracy: 0.7143, Validation F1: 0.6500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 15/15 [00:26<00:00,  1.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch [15/15], Train Loss: 0.3390, Validation Loss: 0.6063, Validation Accuracy: 0.6905, Validation F1: 0.6677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6LQWsoeZRwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7af3e040-0c7b-4be2-a3e9-cb739131e245"
      },
      "source": [
        "best_model = CNN_Text(vocabulary_size, embedding_dim, output_size, kernels_num, kernel_sizes, dropout).to(device)\n",
        "best_model.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/CNN_TEXT_15.pt')['state_dict'])\n",
        "test_loss, test_acc, test_f1 = evaluate(best_model, test_iter, criterion)\n",
        "print('Final Test Scores:', 'Loss:',test_loss, '| Accuracy:',test_acc, \"| F1 score:\",test_f1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Test Scores: Loss: 0.6688445806503296 | Accuracy: 0.611764705882353 | F1 score: 0.5838896306186026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NxjQYQGEMeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}