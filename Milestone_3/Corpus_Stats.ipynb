{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eco_news_pd = pd.read_json('datasetEconomyNews_PN.json')\n",
    "headlines = eco_news_pd['headlineTitle']\n",
    "texts = eco_news_pd['headlineText']\n",
    "labels = eco_news_pd['classification']\n",
    "\n",
    "headlines_df = pd.DataFrame(list(zip(headlines, labels)), columns = ['X_text', 'y_label'])\n",
    "texts_df = pd.DataFrame(list(zip(texts, labels)), columns = ['X_text', 'y_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class Balance (1 for possitive, -1 for negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion of Dataset Made up of Negatives: 0.6227758007117438\n"
     ]
    }
   ],
   "source": [
    "print(\"Portion of Dataset Made up of Negatives:\",len(eco_news_pd[eco_news_pd['classification'] == -1])/len(eco_news_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion of Dataset Made up of Positives: 0.37722419928825623\n"
     ]
    }
   ],
   "source": [
    "print(\"Portion of Dataset Made up of Positives:\",len(eco_news_pd[eco_news_pd['classification'] == 1])/len(eco_news_pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Length Statisics\n",
    "\n",
    "Each example within the dataset has a headline and a short text. The headlines are typically one sentence, while the texts are somewhat longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length of headlines: 58.596085409252666\n",
      "Maximum sequence length of headlines: 101\n",
      "Minimum sequence length of headlines: 17\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "length_headlines = [len(txt) for txt in eco_news_pd['headlineTitle']]\n",
    "print(\"Average sequence length of headlines:\",np.mean(length_headlines))\n",
    "print(\"Maximum sequence length of headlines:\",np.max(length_headlines))\n",
    "print(\"Minimum sequence length of headlines:\",np.min(length_headlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sequence length of texts: 172.65302491103202\n",
      "Maximum sequence length of texts: 295\n",
      "Minimum sequence length of texts: 53\n"
     ]
    }
   ],
   "source": [
    "length_headlines = [len(txt) for txt in eco_news_pd['headlineText']]\n",
    "print(\"Average sequence length of texts:\",np.mean(length_headlines))\n",
    "print(\"Maximum sequence length of texts:\",np.max(length_headlines))\n",
    "print(\"Minimum sequence length of texts:\",np.min(length_headlines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities in Texts and Headlines\n",
    "\n",
    "There are some similarities between texts and headlines within each example. This is taking into account that when we tokenize we make all tokens lowercased, as well as only checking for similarities in tokens that are not stop words or punctuation. Since text sequences are typically longer than headline sequences, we mostly want to know how much of the headline could be represented in the text, (in terms of simple token overlap). Additionally, we should be limiting our input sequence length to a set amount, as to limit the amount of padding if we were to seperate headlines and texts as seperate examples. The limit we are setting for our sequence length is 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average amount of tokens overlapping: 1.5729537366548043\n",
      "Average ratio of overlapping tokens from headlines within texts: 0.2587969809944899\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "stop_words = set(stopwords.words('english'))\n",
    "intersect_words = defaultdict(int)\n",
    "intersect = []\n",
    "intersect_ratio = []\n",
    "for i in range(len(eco_news_pd['headlineText'])):\n",
    "    headline_ = eco_news_pd['headlineTitle'][i].split(' ')[:32]\n",
    "    text_ = eco_news_pd['headlineText'][i].split(' ')[:32]\n",
    "    text = set([word.lower() for word in text_ if word.lower() not in stop_words and word.isalpha()])\n",
    "    headline = set([word.lower() for word in headline_ if word.lower() not in stop_words and word.isalpha()])\n",
    "    if headline & text:\n",
    "        intersecting = headline & text\n",
    "        for word in intersecting:\n",
    "            intersect_words[word] += 1\n",
    "            \n",
    "        intersect.append(len(headline & text))\n",
    "        intersect_ratio.append(len(headline & text) / (len(headline)))\n",
    "    else:\n",
    "        intersect.append(0)\n",
    "        intersect_ratio.append(0)\n",
    "\n",
    "print('Average amount of tokens overlapping:',np.mean(intersect))\n",
    "print('Average ratio of overlapping tokens from headlines within texts:',np.mean(intersect_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bottom 50 overlapping tokens that don't typically occure often throughout the data are listed below. As you can see, some of these are pronouns and many are nouns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252            buy\n",
       "328        demands\n",
       "327           ease\n",
       "326          curbs\n",
       "325        backing\n",
       "324        retains\n",
       "323    supervisory\n",
       "322          april\n",
       "321            max\n",
       "320         flight\n",
       "319      ethiopian\n",
       "318       software\n",
       "317       deciding\n",
       "316        manager\n",
       "315            dam\n",
       "314           told\n",
       "313        session\n",
       "312         choppy\n",
       "311           debt\n",
       "310          needs\n",
       "309         reduce\n",
       "308           papa\n",
       "307       forecast\n",
       "306         powell\n",
       "305        resorts\n",
       "304         nevada\n",
       "330             jp\n",
       "331           lira\n",
       "332         denies\n",
       "335          point\n",
       "369         bubble\n",
       "368         attack\n",
       "367          syria\n",
       "366         public\n",
       "365      companies\n",
       "364        fastest\n",
       "363           grew\n",
       "360       declines\n",
       "359          larry\n",
       "358          state\n",
       "357         latest\n",
       "356           show\n",
       "303           wynn\n",
       "355        figures\n",
       "353        revival\n",
       "350           time\n",
       "348     treasuries\n",
       "347       criminal\n",
       "346        defense\n",
       "345             co\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "intersect_df = pd.DataFrame(list(zip(intersect_words.keys(), intersect_words.values())), columns = ['word', 'freq'])\n",
    "intersect_df.sort_values(by=['freq'], ascending=True)['word'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the top 50 words that overlap between text and headline many times throughout the data. Some of these words are also typically pronouns and many are nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349        stocks\n",
       "86          stock\n",
       "34        economy\n",
       "17       economic\n",
       "23         market\n",
       "20        markets\n",
       "0           china\n",
       "123          wall\n",
       "16         global\n",
       "45          trade\n",
       "65          trump\n",
       "11         growth\n",
       "125        street\n",
       "127        shares\n",
       "14            oil\n",
       "62        billion\n",
       "156        boeing\n",
       "102         sales\n",
       "7             tax\n",
       "376            us\n",
       "99          first\n",
       "124       percent\n",
       "4             fed\n",
       "67        sources\n",
       "56          tesla\n",
       "378          data\n",
       "52      investors\n",
       "68         huawei\n",
       "82        million\n",
       "31          rates\n",
       "8            tech\n",
       "229        profit\n",
       "18       shutdown\n",
       "381     recession\n",
       "48         prices\n",
       "225         world\n",
       "41          steel\n",
       "81           bond\n",
       "235      airlines\n",
       "144        nasdaq\n",
       "145          bear\n",
       "206          baby\n",
       "77            new\n",
       "33        tariffs\n",
       "373      business\n",
       "154           air\n",
       "94       optimism\n",
       "100          weak\n",
       "96     settlement\n",
       "451       buffett\n",
       "Name: word, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "intersect_df = pd.DataFrame(list(zip(intersect_words.keys(), intersect_words.values())), columns = ['word', 'freq'])\n",
    "intersect_df.sort_values(by=['freq'], ascending=False)['word'][:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens Occuring in Positive and Negative Examples\n",
    "\n",
    "It can be helpful to explore the nature of both negative and positive examples for further understand of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent 25 Words in Negative Examples\n",
      "55           stock\n",
      "137       economic\n",
      "549         stocks\n",
      "16         economy\n",
      "257         market\n",
      "188         global\n",
      "268        markets\n",
      "161       business\n",
      "92          growth\n",
      "77           trade\n",
      "52             new\n",
      "75           china\n",
      "94           trump\n",
      "225      investors\n",
      "864        company\n",
      "81            said\n",
      "233          could\n",
      "253             us\n",
      "35      government\n",
      "241      financial\n",
      "1053          fell\n",
      "164            may\n",
      "264         prices\n",
      "955         friday\n",
      "195           data\n",
      "Name: word, dtype: object \n",
      "\n",
      "Least Frequent 25 Words in Negative Examples\n",
      "2502      estimates\n",
      "1531        richard\n",
      "1530       facility\n",
      "1526       tailings\n",
      "1525           ceos\n",
      "1522    contraction\n",
      "1521      undergoes\n",
      "1520       capacity\n",
      "1519         tonnes\n",
      "1517          wrong\n",
      "1516          taken\n",
      "1514          skids\n",
      "1513    steelmakers\n",
      "2346            rbs\n",
      "1509          judge\n",
      "1504           cope\n",
      "1503      carmakers\n",
      "1502      supplying\n",
      "1501       contract\n",
      "1500     automobile\n",
      "1499        changan\n",
      "1498          joint\n",
      "1497            job\n",
      "1495             jv\n",
      "1494         worsen\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "negative_counts = defaultdict(int)\n",
    "positive_counts = defaultdict(int)\n",
    "for i in range(len(eco_news_pd)):\n",
    "\n",
    "    head = eco_news_pd['headlineTitle'][i].split(' ')[:32]\n",
    "    text = eco_news_pd['headlineText'][i].split(' ')[:32]\n",
    "    for j in range(len(head)):\n",
    "        if head[j].lower() not in stop_words and head[j].isalpha():\n",
    "            if eco_news_pd['classification'][i] == -1:\n",
    "                negative_counts[head[j].lower()] += 1\n",
    "            else:\n",
    "                positive_counts[head[j].lower()] += 1\n",
    "    for j in range(len(text)):\n",
    "        if text[j].lower() not in stop_words and text[j].isalpha():\n",
    "            if eco_news_pd['classification'][i] == -1:\n",
    "                negative_counts[text[j].lower()] += 1\n",
    "            else:\n",
    "                positive_counts[text[j].lower()] += 1\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "neg_word_df = pd.DataFrame(list(zip(negative_counts.keys(), negative_counts.values())), columns = ['word', 'freq'])\n",
    "print(\"Most Frequent 25 Words in Negative Examples\")\n",
    "print(neg_word_df.sort_values(by=['freq'], ascending=False)['word'][:25], '\\n')\n",
    "print(\"Least Frequent 25 Words in Negative Examples\")\n",
    "print(neg_word_df.sort_values(by=['freq'], ascending=True)['word'][:25])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Frequent 25 Words in Positive Examples\n",
      "142        stocks\n",
      "76        economy\n",
      "184         stock\n",
      "216      business\n",
      "103      economic\n",
      "60         market\n",
      "53         growth\n",
      "221       company\n",
      "8            said\n",
      "10          trade\n",
      "0           china\n",
      "128     investors\n",
      "45            new\n",
      "177       billion\n",
      "446          wall\n",
      "408       percent\n",
      "469        shares\n",
      "409          rise\n",
      "6       president\n",
      "447        street\n",
      "117        global\n",
      "211          year\n",
      "7           trump\n",
      "61     investment\n",
      "341       markets\n",
      "Name: word, dtype: object \n",
      "\n",
      "Least Frequent 25 Words in Positive Examples\n",
      "1797      producer\n",
      "1138     christmas\n",
      "1137          epic\n",
      "1136       history\n",
      "1134         soars\n",
      "1132      continue\n",
      "1125    especially\n",
      "1124      backdrop\n",
      "1123         bleak\n",
      "1139           eve\n",
      "1122       learned\n",
      "1119      february\n",
      "1118          huya\n",
      "1116          lyft\n",
      "1115        circle\n",
      "1114        losers\n",
      "1113       enjoyed\n",
      "1112         cheap\n",
      "1110        reason\n",
      "1120          came\n",
      "1141         white\n",
      "1142         house\n",
      "1143       adviser\n",
      "1167          vows\n",
      "1166         shoot\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pos_word_df = pd.DataFrame(list(zip(positive_counts.keys(), positive_counts.values())), columns = ['word', 'freq'])\n",
    "print(\"Most Frequent 25 Words in Positive Examples\")\n",
    "print(pos_word_df.sort_values(by=['freq'], ascending=False)['word'][:25], '\\n')\n",
    "print(\"Least Frequent 25 Words in Positive Examples\")\n",
    "print(pos_word_df.sort_values(by=['freq'], ascending=True)['word'][:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to observe that words appearing often, occur in both kinds of classes. However words that do not appear often do not appear in both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portion of words from positive examples that occur also in negative examples\n",
      "0.5100111234705228\n"
     ]
    }
   ],
   "source": [
    "print(\"Portion of words from positive examples that occur also in negative examples\")\n",
    "print(len(set(negative_counts.keys()) & set(positive_counts.keys())) / len(positive_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 words that occur in positive examples, but not negative examples, multiple times:\n",
      "talk | frequency: 3\n",
      "gaining | frequency: 2\n",
      "field | frequency: 2\n",
      "star | frequency: 3\n",
      "stood | frequency: 2\n",
      "comes | frequency: 2\n",
      "shoppers | frequency: 2\n",
      "delivery | frequency: 2\n",
      "far | frequency: 3\n",
      "november | frequency: 3\n",
      "opportunity | frequency: 2\n",
      "lead | frequency: 2\n",
      "lift | frequency: 6\n",
      "headquarters | frequency: 2\n",
      "working | frequency: 3\n",
      "rather | frequency: 2\n",
      "conservation | frequency: 2\n",
      "solid | frequency: 7\n",
      "sovereign | frequency: 2\n",
      "professional | frequency: 2\n",
      "reversing | frequency: 2\n",
      "responsibility | frequency: 2\n",
      "hard | frequency: 3\n",
      "online | frequency: 4\n",
      "revival | frequency: 3\n",
      "\n",
      "25 words that occur in negative examples, but not positive examples, multiple times:\n",
      "pause | frequency: 2\n",
      "minutes | frequency: 3\n",
      "january | frequency: 3\n",
      "meeting | frequency: 4\n",
      "showing | frequency: 4\n",
      "express | frequency: 2\n",
      "enough | frequency: 4\n",
      "warning | frequency: 6\n",
      "democrats | frequency: 2\n",
      "proposal | frequency: 4\n",
      "support | frequency: 2\n",
      "party | frequency: 2\n",
      "challenges | frequency: 5\n",
      "offers | frequency: 2\n",
      "sides | frequency: 2\n",
      "deep | frequency: 2\n",
      "march | frequency: 5\n",
      "starts | frequency: 2\n",
      "bite | frequency: 2\n",
      "steel | frequency: 11\n",
      "manufacturers | frequency: 2\n",
      "calls | frequency: 4\n",
      "restrict | frequency: 2\n",
      "buybacks | frequency: 3\n",
      "spend | frequency: 3\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "print(\"25 words that occur in positive examples, but not negative examples, multiple times:\")\n",
    "for key, value in positive_counts.items():\n",
    "    if key not in negative_counts and value > 1:\n",
    "        print(key, \"| frequency:\",value)\n",
    "        count +=1\n",
    "    if count == 25:\n",
    "        break\n",
    "count = 0\n",
    "print(\"\\n25 words that occur in negative examples, but not positive examples, multiple times:\")\n",
    "for key, value in negative_counts.items():\n",
    "    if key not in positive_counts and value > 1:\n",
    "        print(key, \"| frequency:\",value)\n",
    "        count +=1\n",
    "    if count == 25:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
